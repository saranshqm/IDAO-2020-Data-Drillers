{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost\n",
    "import csv as csv\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "#from sklearn.cross_validation import  train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.grid_search import GridSearchCV2 #Perforing grid search\n",
    "from scipy.stats import skew\n",
    "from collections import OrderedDict\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from catboost import CatBoostRegressor\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649912, 15) (284071, 9)\n"
     ]
    }
   ],
   "source": [
    "#loading train and test data-set\n",
    "\n",
    "train = pd.read_csv(\"file:///D:/data%20analysis/COMPETITIONS%202020/IDAO%202020/IDAO%202020/train.csv\",header=0)\n",
    "test = pd.read_csv(\"file:///D:/data%20analysis/COMPETITIONS%202020/IDAO%202020/IDAO%202020/Track%201/test.csv\",header=0)\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting date, time, hour......for train data\n",
      "extraction of date_time_hour done.........!!\n",
      "extracting date, time, hour......for test data\n",
      "extraction of date_time_hour done.........!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def date_time_extract(a,count):\n",
    "    if count == 0:\n",
    "        print('extracting date, time, hour......for train data')\n",
    "        train['hour'] = pd.DatetimeIndex(a).hour\n",
    "        train['minute'] = pd.DatetimeIndex(a).minute\n",
    "        train['second'] = pd.DatetimeIndex(a).second\n",
    "        train['day'] = pd.DatetimeIndex(a).day\n",
    "        print('extraction of date_time_hour done.........!!')\n",
    "    else:\n",
    "        print('extracting date, time, hour......for test data')\n",
    "        test['hour'] = pd.DatetimeIndex(a).hour\n",
    "        test['minute'] = pd.DatetimeIndex(a).minute\n",
    "        test['second'] = pd.DatetimeIndex(a).second\n",
    "        test['day'] = pd.DatetimeIndex(a).day\n",
    "        print('extraction of date_time_hour done.........!!')\n",
    "    \n",
    "    count+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "date_time_extract(train['epoch'],0)\n",
    "date_time_extract(test['epoch'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acceleration(a,b,c,count):\n",
    "    a1 = []\n",
    "    a2 = []\n",
    "    a3 = []\n",
    "    \n",
    "    #a1.append(0)\n",
    "    #a2.append(0)\n",
    "    #a3.append(0)\n",
    "    \n",
    "    a1 = np.asarray(a)\n",
    "    a2 = np.asarray(b)\n",
    "    a3 = np.asarray(c)\n",
    "    \n",
    "    b1 = []\n",
    "    b2 = []\n",
    "    b3 = []\n",
    "    \n",
    "    if count == 0:\n",
    "    \n",
    "        for i in range(len(np.asarray(train['hour']))-1):\n",
    "            #print('extracting acceleration in 3-D....')\n",
    "            b1.append((a1[i+1]-a1[i]))\n",
    "            b2.append((a2[i+1]-a2[i]))\n",
    "            b3.append((a3[i+1]-a3[i]))\n",
    "        \n",
    "        b1.append(a[len(a)-1])\n",
    "        b2.append(b[len(a)-1])\n",
    "        b3.append(c[len(a)-1])\n",
    "    \n",
    "        print('extraction done!!')\n",
    "    \n",
    "        print('loading acceleration values in train...')\n",
    "        train['a_x'] = np.asarray(b1)\n",
    "        train['a_y'] = np.asarray(b2)\n",
    "        train['a_z'] = np.asarray(b3)\n",
    "        print('loaded acc values in train...')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(len(np.asarray(test['hour']))-1):\n",
    "            #print('extracting acceleration in 3-D....')\n",
    "            b1.append((a1[i+1]-a1[i]))\n",
    "            b2.append((a2[i+1]-a2[i]))\n",
    "            b3.append((a3[i+1]-a3[i]))\n",
    "        \n",
    "        b1.append(a[len(a)-1])\n",
    "        b2.append(b[len(a)-1])\n",
    "        b3.append(c[len(a)-1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print('loading acceleration values in test')\n",
    "        test['a_x'] = np.asarray(b1)\n",
    "        test['a_y'] = np.asarray(b2)\n",
    "        test['a_z'] = np.asarray(b3)\n",
    "        print('loaded acc values in test')\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction done!!\n",
      "loading acceleration values in train...\n",
      "loaded acc values in train...\n",
      "loading acceleration values in test\n",
      "loaded acc values in test\n"
     ]
    }
   ],
   "source": [
    "get_acceleration(train['Vx_sim'],train['Vy_sim'],train['Vz_sim'],0)\n",
    "get_acceleration(test['Vx_sim'],test['Vy_sim'],test['Vz_sim'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(t,count):\n",
    "    if count == 0:\n",
    "        feature_df_train = train[['Vx_sim', 'Vy_sim', 'Vz_sim', 'x_sim', 'y_sim', 'z_sim','a_x','a_y','a_z']]\n",
    "        return feature_df_train\n",
    "    \n",
    "    else:\n",
    "        feature_df_test = test[['Vx_sim', 'Vy_sim', 'Vz_sim', 'x_sim', 'y_sim', 'z_sim','a_x','a_y','a_z']]\n",
    "        return feature_df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = get_features(train,0)\n",
    "x_train = np.asarray(x_train)\n",
    "x_test = get_features(test,1)\n",
    "x_test = np.asarray(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_variable(x):\n",
    "    return np.asarray(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_x = get_target_variable(train['x'])\n",
    "y_y = get_target_variable(train['y'])\n",
    "y_z = get_target_variable(train['z'])\n",
    "\n",
    "y_vx = get_target_variable(train['Vx'])\n",
    "y_vy = get_target_variable(train['Vy'])\n",
    "y_vz = get_target_variable(train['Vz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_split,x_val_split,y_train_x,y_val_x,y_train_y,y_val_y,y_train_z,y_val_z,y_train_vx, y_val_vx,y_train_vy,y_val_vy, y_train_vz,y_val_vz = train_test_split(x_train,y_x,y_y,y_z,y_vx,y_vy,y_vz,test_size = 0.3,random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### defining the score\n",
    "\n",
    "def smape(satellite_predicted_values, satellite_true_values): \n",
    "    # the division, addition and subtraction are pointwise \n",
    "    beta = np.mean(np.abs((satellite_predicted_values - satellite_true_values) \n",
    "        / (np.abs(satellite_predicted_values) + np.abs(satellite_true_values))))\n",
    "    return 100*(1-beta)\n",
    "\n",
    "def Mean_abs_error(Y_true,Y_pred):\n",
    "    \n",
    "    return mean_absolute_error(Y_true,Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# this is best till now\\n#n_estimators = 3000\\n#max_depth = 8\\n\\ndef xgb_model_evaluation(x_train_split,x_val_split,y_train_x,y_val_x,x_test):\\n    #n_Estimators = 10000\\n    model = xgboost.XGBRegressor(colsample_bytree=0.4,\\n                 gamma=0,                 \\n                 learning_rate=0.1,\\n                 max_depth=8,\\n                 min_child_weight=1.5,\\n                 n_estimators=3000,                                                                    \\n                 reg_alpha=0.75,\\n                 reg_lambda=0.45,\\n                 subsample=0.6,\\n                 seed=42)\\n    #print('all parameters enabled--->')\\n    print('train for y_train_x !!------>')\\n    \\n    model.fit(x_train_split,y_train_x)\\n    \\n    print('training for y_train_x completed-------->prediction started for y_val_x')\\n    \\n    a = model.predict(x_val_split)\\n    \\n    print('prediction for y_val_x completed------> evaluating result for validation data')\\n    \\n    print('the score for validation obtained is:',smape(a,y_val_x))\\n    print('the Mean_abs_error VALIDATION for train is:', Mean_abs_error(a,y_val_x))\\n    \\n    \\n    print('evaluating results for train---->')\\n    a = model.predict(x_train_split)\\n    print('the smape score for train obtained is:',smape(a,y_train_x))\\n    print('the Mean_abs_error obtained for train is:', Mean_abs_error(a,y_train_x))\\n    print('prediction of test has been started')\\n    \\n    a = np.asarray(model.predict(x_test))\\n    print('test values predicted successfully------> Moving to the next step now')\\n    return a,model\\n    \\n    \\n    \\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# this is best till now\n",
    "#n_estimators = 3000\n",
    "#max_depth = 8\n",
    "\n",
    "def xgb_model_evaluation(x_train_split,x_val_split,y_train_x,y_val_x,x_test):\n",
    "    #n_Estimators = 10000\n",
    "    model = xgboost.XGBRegressor(colsample_bytree=0.4,\n",
    "                 gamma=0,                 \n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=8,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=3000,                                                                    \n",
    "                 reg_alpha=0.75,\n",
    "                 reg_lambda=0.45,\n",
    "                 subsample=0.6,\n",
    "                 seed=42)\n",
    "    #print('all parameters enabled--->')\n",
    "    print('train for y_train_x !!------>')\n",
    "    \n",
    "    model.fit(x_train_split,y_train_x)\n",
    "    \n",
    "    print('training for y_train_x completed-------->prediction started for y_val_x')\n",
    "    \n",
    "    a = model.predict(x_val_split)\n",
    "    \n",
    "    print('prediction for y_val_x completed------> evaluating result for validation data')\n",
    "    \n",
    "    print('the score for validation obtained is:',smape(a,y_val_x))\n",
    "    print('the Mean_abs_error VALIDATION for train is:', Mean_abs_error(a,y_val_x))\n",
    "    \n",
    "    \n",
    "    print('evaluating results for train---->')\n",
    "    a = model.predict(x_train_split)\n",
    "    print('the smape score for train obtained is:',smape(a,y_train_x))\n",
    "    print('the Mean_abs_error obtained for train is:', Mean_abs_error(a,y_train_x))\n",
    "    print('prediction of test has been started')\n",
    "    \n",
    "    a = np.asarray(model.predict(x_test))\n",
    "    print('test values predicted successfully------> Moving to the next step now')\n",
    "    return a,model\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is best till now\n",
    "#n_estimators = 10000\n",
    "#num_leaves = 80\n",
    "#learning_rate = 0.05\n",
    "\n",
    "def lgb_model_evaluation(x_train_split,x_val_split,y_train_x,y_val_x,x_test):\n",
    "    #n_Estimators = 10000\n",
    "    #LGBMRegressor\n",
    "    model = lgb.LGBMRegressor(objective='regression',\n",
    "    num_leaves=100,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=15000)\n",
    "    \n",
    "    \n",
    "    #print('all parameters enabled--->')\n",
    "    print('train for y_train_x !!------>')\n",
    "    \n",
    "    model.fit(x_train_split,y_train_x)\n",
    "    \n",
    "    print('training for y_train_x completed-------->prediction started for y_val_x')\n",
    "    \n",
    "    a = model.predict(x_val_split)\n",
    "    \n",
    "    print('prediction for y_val_x completed------> evaluating result for validation data')\n",
    "    \n",
    "    print('the score for validation obtained is:',smape(a,y_val_x))\n",
    "    print('the Mean_abs_error VALIDATION for train is:', Mean_abs_error(a,y_val_x))\n",
    "    \n",
    "    \n",
    "    print('evaluating results for train---->')\n",
    "    a = model.predict(x_train_split)\n",
    "    print('the smape score for train obtained is:',smape(a,y_train_x))\n",
    "    print('the Mean_abs_error obtained for train is:', Mean_abs_error(a,y_train_x))\n",
    "    print('prediction of test has been started')\n",
    "    \n",
    "    a = np.asarray(model.predict(x_test))\n",
    "    print('test values predicted successfully------> Moving to the next step now')\n",
    "    return a,model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for y_train_x !!------>\n",
      "training for y_train_x completed-------->prediction started for y_val_x\n",
      "prediction for y_val_x completed------> evaluating result for validation data\n",
      "the score for validation obtained is: 95.52708763028306\n",
      "the Mean_abs_error VALIDATION for train is: 724.5130116996994\n",
      "evaluating results for train---->\n",
      "the smape score for train obtained is: 96.53945754848735\n",
      "the Mean_abs_error obtained for train is: 483.98537046714284\n",
      "prediction of test has been started\n",
      "test values predicted successfully------> Moving to the next step now\n"
     ]
    }
   ],
   "source": [
    "# xgb model for y_train_x\n",
    "y_test_x, model_x = lgb_model_evaluation(x_train_split,x_val_split,y_train_x,y_val_x,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for y_train_x !!------>\n",
      "training for y_train_x completed-------->prediction started for y_val_x\n",
      "prediction for y_val_x completed------> evaluating result for validation data\n",
      "the score for validation obtained is: 95.33226166666987\n",
      "the Mean_abs_error VALIDATION for train is: 754.9813383445877\n",
      "evaluating results for train---->\n",
      "the smape score for train obtained is: 96.38282465293541\n",
      "the Mean_abs_error obtained for train is: 493.96901342095333\n",
      "prediction of test has been started\n",
      "test values predicted successfully------> Moving to the next step now\n"
     ]
    }
   ],
   "source": [
    "# xgb model for y_train_y\n",
    "y_test_y, model_y =lgb_model_evaluation(x_train_split,x_val_split,y_train_y,y_val_y,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for y_train_x !!------>\n",
      "training for y_train_x completed-------->prediction started for y_val_x\n",
      "prediction for y_val_x completed------> evaluating result for validation data\n",
      "the score for validation obtained is: 94.57048949939811\n",
      "the Mean_abs_error VALIDATION for train is: 555.2353672965229\n",
      "evaluating results for train---->\n",
      "the smape score for train obtained is: 95.63759833432546\n",
      "the Mean_abs_error obtained for train is: 371.13239698325253\n",
      "prediction of test has been started\n",
      "test values predicted successfully------> Moving to the next step now\n"
     ]
    }
   ],
   "source": [
    "# xgb model for y_train_x\n",
    "y_test_z, model_z = lgb_model_evaluation(x_train_split,x_val_split,y_train_z,y_val_z,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for y_train_x !!------>\n",
      "training for y_train_x completed-------->prediction started for y_val_x\n",
      "prediction for y_val_x completed------> evaluating result for validation data\n",
      "the score for validation obtained is: 95.53128680876983\n",
      "the Mean_abs_error VALIDATION for train is: 0.07217995822414498\n",
      "evaluating results for train---->\n",
      "the smape score for train obtained is: 96.58181981190091\n",
      "the Mean_abs_error obtained for train is: 0.049748451747584466\n",
      "prediction of test has been started\n",
      "test values predicted successfully------> Moving to the next step now\n"
     ]
    }
   ],
   "source": [
    "# xgb model for y_train_vx\n",
    "y_test_vx, model_vx = lgb_model_evaluation(x_train_split,x_val_split,y_train_vx,y_val_vx,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for y_train_x !!------>\n",
      "training for y_train_x completed-------->prediction started for y_val_x\n",
      "prediction for y_val_x completed------> evaluating result for validation data\n",
      "the score for validation obtained is: 95.4764360361155\n",
      "the Mean_abs_error VALIDATION for train is: 0.0742793874131463\n",
      "evaluating results for train---->\n",
      "the smape score for train obtained is: 96.47635722896962\n",
      "the Mean_abs_error obtained for train is: 0.051523038516330034\n",
      "prediction of test has been started\n",
      "test values predicted successfully------> Moving to the next step now\n"
     ]
    }
   ],
   "source": [
    "# xgb model for y_train_vy\n",
    "y_test_vy, model_vy = lgb_model_evaluation(x_train_split,x_val_split,y_train_vy,y_val_vy,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for y_train_x !!------>\n",
      "training for y_train_x completed-------->prediction started for y_val_x\n",
      "prediction for y_val_x completed------> evaluating result for validation data\n",
      "the score for validation obtained is: 94.56553171669574\n",
      "the Mean_abs_error VALIDATION for train is: 0.05562930803806017\n",
      "evaluating results for train---->\n",
      "the smape score for train obtained is: 95.72860059690234\n",
      "the Mean_abs_error obtained for train is: 0.039489822826401406\n",
      "prediction of test has been started\n",
      "test values predicted successfully------> Moving to the next step now\n"
     ]
    }
   ],
   "source": [
    "# xgb model for y_train_vz\n",
    "y_test_vz, model_vz = lgb_model_evaluation(x_train_split,x_val_split,y_train_vz,y_val_vz,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284071,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_vx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284071, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# just sending simulated values as the answer\n",
    "#submission = test[[\"id\"]]\n",
    "#test = pd.read_csv(\"/content/drive/My Drive/IDAO 2020/IDAO 2020/Track 1/test.csv\",header=0)\n",
    "test = pd.read_csv(\"file:///D:/data%20analysis/COMPETITIONS%202020/IDAO%202020/IDAO%202020/Track%201/test.csv\",header=0)\n",
    "test = test.drop('sat_id',axis=1)\n",
    "test = test.drop('epoch',axis=1)\n",
    "\n",
    "idd = np.asarray(test['id'])\n",
    "\n",
    "\n",
    "\n",
    "submissio = test[[\"id\", \"x_sim\", \"y_sim\", \"z_sim\", \"Vx_sim\", \"Vy_sim\", \"Vz_sim\"]]\n",
    "submissio.columns = [\"id\", \"x\", \"y\", \"z\", \"Vx\", \"Vy\", \"Vz\"]\n",
    "test = test[:0]\n",
    "\n",
    "submissio['id'] = idd\n",
    "submissio['x'] = np.asarray(y_test_x)\n",
    "submissio['y'] = np.asarray(y_test_y)\n",
    "submissio['z'] = np.asarray(y_test_z)\n",
    "\n",
    "submissio['Vx'] = np.asarray(y_test_vx)\n",
    "submissio['Vy'] = np.asarray(y_test_vy)\n",
    "submissio['Vz'] = np.asarray(y_test_vz)\n",
    "\n",
    "submissio.to_csv(\"D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\\submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARANSH\\Anaconda3\\envs\\saransh\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving our model to D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\u0007ttempt 1\n",
      "models saved-----> now they are ready to be used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Load the model from the file \\nknn_from_joblib = joblib.load('filename.pkl')  \\n  \\n# Use the loaded model to make predictions \\nknn_from_joblib.predict(X_test)\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## saving our model to D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\\\n",
    "\n",
    "import pickle \n",
    "\n",
    "from sklearn.externals import joblib \n",
    "# Save the trained model as a pickle string. \n",
    "\n",
    "print('saving our model to D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\\attempt 1')\n",
    "\n",
    "model_x_saved = joblib.dump(model_x, 'D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\\model_x.pkl') \n",
    "model_y_saved = joblib.dump(model_y, 'D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\\model_y.pkl') \n",
    "model_z_saved = joblib.dump(model_z, 'D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\\model_z.pkl') \n",
    "    \n",
    "model_vx_saved = joblib.dump(model_vx, 'D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\\model_vx.pkl') \n",
    "model_vy_saved = joblib.dump(model_vy, 'D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\\model_vy.pkl') \n",
    "model_vz_saved = joblib.dump(model_vz, 'D:\\data analysis\\COMPETITIONS 2020\\IDAO 2020\\IDAO 2020\\Track 2\\my submissions\\model_vz.pkl') \n",
    "\n",
    "print('models saved-----> now they are ready to be used')\n",
    "\n",
    "\"\"\"\n",
    "# Load the model from the file \n",
    "knn_from_joblib = joblib.load('filename.pkl')  \n",
    "  \n",
    "# Use the loaded model to make predictions \n",
    "knn_from_joblib.predict(X_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.externals import joblib \\nmodel_x = joblib.load('D:\\\\data analysis\\\\COMPETITIONS 2020\\\\IDAO 2020\\\\IDAO 2020\\\\Track 2\\\\my submissions\\\\attempt 1\\\\n_es = 3000, xgb\\\\model_x.pkl')\\n\\n\\nx_test = test[['Vx_sim', 'Vy_sim', 'Vz_sim', 'x_sim', 'y_sim', 'z_sim','a_x','a_y','a_z']]\\n\\nmodel_x.predict(np.asarray(x_test[:150]))\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##loading the saved model\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.externals import joblib \n",
    "model_x = joblib.load('D:\\\\data analysis\\\\COMPETITIONS 2020\\\\IDAO 2020\\\\IDAO 2020\\\\Track 2\\\\my submissions\\\\attempt 1\\\\n_es = 3000, xgb\\\\model_x.pkl')\n",
    "\n",
    "\n",
    "x_test = test[['Vx_sim', 'Vy_sim', 'Vz_sim', 'x_sim', 'y_sim', 'z_sim','a_x','a_y','a_z']]\n",
    "\n",
    "model_x.predict(np.asarray(x_test[:150]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['a_x']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
